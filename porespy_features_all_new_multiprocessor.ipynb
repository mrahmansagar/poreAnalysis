{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35bf8e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "from tkinter import Tcl # for sorting the slices as in windows dir\n",
    "from glob import glob \n",
    "from tqdm.notebook import tqdm \n",
    "import pandas as pd \n",
    "\n",
    "from poreUtils import *\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from scipy import ndimage as nd\n",
    "from skimage.measure import label\n",
    "#from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import watershed\n",
    "\n",
    "import json \n",
    "\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ea239b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using porespy \n",
    "import porespy as ps\n",
    "import scipy.ndimage as spim\n",
    "ps.visualization.set_mpl_style()\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a26fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all the folders where there rois \n",
    "\n",
    "# data dir \n",
    "data_dir = 'E:\\\\Data\\\\sam_data\\\\new'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e43d553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the sample folder where there are rois \n",
    "sample_folders = os.listdir(data_dir)\n",
    "\n",
    "all_rois = []\n",
    "valid_folders = []\n",
    "for d in sample_folders:\n",
    "    roi_path = os.path.join(data_dir, d, 'roi')\n",
    "    if (os.path.exists(roi_path)):\n",
    "        valid_folders.append(os.path.join(data_dir, d,))\n",
    "        all_rois += glob((roi_path +'\\*'))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e98812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the rois that are already processed and remove them from the list of rois \n",
    "porespy_processed_dth10 = []\n",
    "\n",
    "for p in sample_folders:\n",
    "    porespy_path = os.path.join(data_dir, p, 'porespy') \n",
    "    porespy_processed_dth10 += glob((porespy_path + '\\*_dth10.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4d03b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(porespy_processed_dth10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b0dd6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the ones that are already processed \n",
    "for apfile in porespy_processed_dth10:\n",
    "    all_rois.remove(apfile.replace('porespy', 'roi').split('_bth')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcd64e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1732"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2df2169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a separate folder to put porespy restult\n",
    "\n",
    "for s in valid_folders:\n",
    "    if not os.path.exists(os.path.join(s, 'porespy')):\n",
    "        os.makedirs(os.path.join(s, 'porespy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "537fae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_process(path_roi):\n",
    "    \n",
    "    bin_th = 55\n",
    "    dt_th = 10\n",
    "    \n",
    "    try:\n",
    "        print('processing....', path_roi)\n",
    "        \n",
    "        tiffs = os.listdir(path_roi)\n",
    "        slices = Tcl().call('lsort', '-dict', tiffs)\n",
    "        vol = np.empty(shape=(300, 300, 300), dtype=np.uint8)\n",
    "        # Temporary list to hold blank slices\n",
    "        blank_slices = []\n",
    "\n",
    "        for i, fname in enumerate(slices):\n",
    "            im = Image.open(os.path.join(path_roi, fname))\n",
    "            imarray = np.array(im)\n",
    "            \n",
    "            if np.all(imarray == 0):\n",
    "                blank_slices.append(imarray)\n",
    "            else:\n",
    "                vol[i - len(blank_slices), :, :] = imarray\n",
    "\n",
    "\n",
    "        # Append blank slices at the end\n",
    "        if len(blank_slices) > 0:\n",
    "            vol[-len(blank_slices):] = blank_slices\n",
    "\n",
    "        th_vol = vol < bin_th\n",
    "        th_vol = nd.binary_fill_holes(th_vol, np.ones((3,3,3)))\n",
    "        th_vol = nd.binary_closing(th_vol, np.ones((3,3,3)))\n",
    "        dt3d = nd.distance_transform_edt(th_vol)\n",
    "\n",
    "\n",
    "\n",
    "        mask = dt3d > dt_th\n",
    "        markers = label(mask)\n",
    "        labels = watershed(-dt3d, markers, mask=th_vol)\n",
    "        props = ps.metrics.regionprops_3D(labels)\n",
    "\n",
    "        # Create a list of properties\n",
    "        property_list = ['label', 'volume', 'bbox_volume', 'sphericity', 'surface_area', 'convex_volume',\n",
    "                            'centroid', 'equivalent_diameter_area', 'euler_number', 'extent', \n",
    "                            'axis_major_length', 'axis_minor_length', 'solidity']\n",
    "\n",
    "        # Create a dictionary to store the properties of the current instance of r\n",
    "        properties = {}\n",
    "\n",
    "        for prop in property_list:\n",
    "            properties[prop] = []\n",
    "\n",
    "        # Iterate over each instance of r\n",
    "        for r_instance in props:\n",
    "            # Iterate over the property list\n",
    "            for prop in property_list:\n",
    "                try:\n",
    "                    # Extract the property from the current instance of r\n",
    "                    value = getattr(r_instance, prop)\n",
    "\n",
    "                    if prop == 'centroid':\n",
    "                        # If the property is 'centroid', convert it to the nearest integer\n",
    "                        value = np.round(value).astype(int).tolist()\n",
    "\n",
    "                    properties[prop].append(value)\n",
    "\n",
    "                except AttributeError:\n",
    "                    # If the property does not exist, set it to None\n",
    "                    properties[prop] = None\n",
    "                except NotImplementedError:\n",
    "                    # If there is a NotImplementedError, set it to None and continue to the next iteration\n",
    "                    properties[prop] = None\n",
    "                    continue\n",
    "        \n",
    "        # Create a pandas dataframe from the data list\n",
    "        df = pd.DataFrame(properties)\n",
    "\n",
    "\n",
    "        features = df.to_dict(orient='list')\n",
    "        features['bin_th'] = [bin_th]\n",
    "        features['dt_th'] = [dt_th]\n",
    "        features['dtmax'] = [dt3d.max()]\n",
    "        \n",
    "        jsonString = json.dumps(features)\n",
    "        jsonFile = open(path_roi.replace('roi', 'porespy') + '_bth' + str(bin_th) + '_dth' + str(dt_th) + '.json', 'w')\n",
    "        jsonFile.write(jsonString)\n",
    "        jsonFile.close()        \n",
    "        \n",
    "    except:\n",
    "        print('skipping....', path_roi)\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pool = multiprocessing.Pool(processes=40)\n",
    "    pool.map(parallel_process, all_rois)\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b1cfbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Data\\\\sam_data\\\\new\\\\MD_1264_A10_Z6.6mm\\\\roi\\\\0-300x1000-1300x1000-1300'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rois[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95ff5954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2459f3664f7d431cb06e66adcfeee863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing.... E:\\Data\\sam_data\\new\\MD_1264_A10_Z6.6mm\\roi\\0-300x1000-1300x1000-1300\n"
     ]
    }
   ],
   "source": [
    "bin_th = 55\n",
    "dt_th = 12\n",
    "\n",
    "processed_rois = []\n",
    "faulty_rois = []\n",
    "\n",
    "for roi_path in tqdm(all_rois[0:2]):\n",
    "    try:\n",
    "        print('processing....', roi_path)\n",
    "        \n",
    "        tiffs = os.listdir(roi_path)\n",
    "        slices = Tcl().call('lsort', '-dict', tiffs)\n",
    "        vol = np.empty(shape=(300, 300, 300), dtype=np.uint8)\n",
    "        # Temporary list to hold blank slices\n",
    "        blank_slices = []\n",
    "\n",
    "        for i, fname in enumerate(slices):\n",
    "            im = Image.open(os.path.join(roi_path, fname))\n",
    "            imarray = np.array(im)\n",
    "            \n",
    "            if np.all(imarray == 0):\n",
    "                blank_slices.append(imarray)\n",
    "            else:\n",
    "                vol[i - len(blank_slices), :, :] = imarray\n",
    "\n",
    "        # Append blank slices at the end\n",
    "        if len(blank_slices) > 0:\n",
    "            vol[-len(blank_slices):] = blank_slices\n",
    "\n",
    "        th_vol = vol < bin_th\n",
    "        th_vol = nd.binary_fill_holes(th_vol, np.ones((3,3,3)))\n",
    "        th_vol = nd.binary_closing(th_vol, np.ones((3,3,3)))\n",
    "        \n",
    "        dt3d = nd.distance_transform_edt(th_vol)\n",
    "\n",
    "        mask = dt3d > dt_th\n",
    "        markers = label(mask)\n",
    "        labels = watershed(-dt3d, markers, mask=th_vol)\n",
    "\n",
    "        props = ps.metrics.regionprops_3D(labels)\n",
    "       \n",
    "        # Create a list of properties\n",
    "        property_list = ['label', 'volume', 'bbox_volume', 'sphericity', 'surface_area', 'convex_volume',\n",
    "                            'centroid', 'equivalent_diameter_area', 'euler_number', 'extent', \n",
    "                            'axis_major_length', 'axis_minor_length', 'solidity']\n",
    "\n",
    "        # Create a dictionary to store the properties of the current instance of r\n",
    "        properties = {}\n",
    "\n",
    "        for prop in property_list:\n",
    "            properties[prop] = []\n",
    "\n",
    "        def parallel_process(prop_instance):\n",
    "            # Iterate over the property list\n",
    "            for prop in property_list:\n",
    "                try:\n",
    "                    # Extract the property from the current instance of r\n",
    "                    value = getattr(prop_instance, prop)\n",
    "\n",
    "                    if prop == 'centroid':\n",
    "                        # If the property is 'centroid', convert it to the nearest integer\n",
    "                        value = np.round(value).astype(int).tolist()\n",
    "\n",
    "                    properties[prop].append(value)\n",
    "\n",
    "                except AttributeError:\n",
    "                    # If the property does not exist, set it to None\n",
    "                    properties[prop] = None\n",
    "                except NotImplementedError:\n",
    "                    # If there is a NotImplementedError, set it to None and continue to the next iteration\n",
    "                    properties[prop] = None\n",
    "                    continue\n",
    "\n",
    "        if __name__ == '__main__':\n",
    "            pool = multiprocessing.Pool()\n",
    "            pool.map(parallel_process, props)\n",
    "            pool.close()\n",
    "\n",
    "\n",
    "        # Create a pandas dataframe from the data list\n",
    "        df = pd.DataFrame(properties)\n",
    "\n",
    "        features = df.to_dict(orient='list')\n",
    "        features['bin_th'] = [bin_th]\n",
    "        features['dt_th'] = [dt_th]\n",
    "        features['dtmax'] = [dt3d.max()]\n",
    "        \n",
    "\n",
    "        jsonString = json.dumps(features)\n",
    "        jsonFile = open(roi_path.replace('roi', 'porespy') + '_bth' + str(bin_th) + '_dth' + str(dt_th) + 'v2.json', 'w')\n",
    "        jsonFile.write(jsonString)\n",
    "        jsonFile.close()\n",
    "        \n",
    "    except:\n",
    "        faulty_rois.append(roi_path)\n",
    "        print('skipping....', roi_path)\n",
    "        pass\n",
    "\n",
    "print(faulty_rois)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
